# Project will eveolve slowly using Yolov8 for live object detection maybe will incorporate training to detect new objects and will use llm to recognixe objects and get llm agents working on different tasks. Will try to incorporate tts and stt to make it more interactive.

# this will need:
- cellphone with app installed to stream video from it
- Yolov8 python package from ultralytics
- lmstudio probable or ollama for local llm
- groq for external llm
- postgresql with pgvector for embeddings or just a normal postgresql table with a field that will store embeddings or documents or metadata, need to decide on the architecture and organization
- will try to add detection of hands to simulate commands by hand detection..
